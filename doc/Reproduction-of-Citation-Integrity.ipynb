{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2aa6b5-8253-48f1-bb6e-c20ade5eb851",
   "metadata": {},
   "source": [
    "# Reproduction of Citation-Integrity\n",
    "\n",
    "### Authored by Jeffrey Dick on 2024-11-29\n",
    "\n",
    "This notebook presents my reproduction of the Citation-Integrity model.\n",
    "See [multivers/README.md](https://github.com/jedick/readycite/tree/main/multivers) for details about setting up the model, including sources of data.\n",
    "\n",
    "## Introduction to the model\n",
    "\n",
    "This description was adapted from [Sarol et al. (2024)](https://doi.org/10.1093/bioinformatics/btae420).\n",
    "\n",
    "- [Citation-Integrity](https://github.com/ScienceNLP-Lab/Citation-Integrity) is based on [MultiVerS](https://github.com/dwadden/multivers), which uses the Longformer encoder.\n",
    "    - The data processed by MultiVerS consist of **claims** and **abstracts**. The original model was applied to a version of the SciFact dataset with additional preprocessing for negative sampling ([Wadden et al., 2022](https://doi.org/10.48550/arXiv.2112.01640)).\n",
    "    - The Citation-Integrity dataset consists of **claims** and **evidence**. The evidence is treated like the abstract for the purpose of the MultiVerS model. *This is the dataset used for this notebook.*\n",
    "- MultiVerS performs two tasks independently:\n",
    "    - selection of rationale sentences from the abstracts\n",
    "    - label prediction for the claims\n",
    "- Based on poor performance in experiments, Citation-Integrity ignores the rational sentence selection in MultiVerS by setting the loss function weight to 0.\n",
    "- Compared to MultiVerS, Citation-Integrity adds three tokens to the claims as citation markers:\n",
    "    - [CIT] for the target citation\n",
    "    - [MULTI_CIT] for the target citation among other citations\n",
    "    - [OTHER_CIT] for non-target citations\n",
    "- Unlike MultiVerS, which selects rationale sentences from only the abstracts of cited articles, Citation-Integrity uses the full text of articles.\n",
    "    - The BM25 model is used to retrieve the top 60 sentences.\n",
    "    - The MonoT5 reranker is used to rerank those sentences.\n",
    "    - The top-k (5, 10, or 20 in experiments) sentences are used as evidence sentences.\n",
    "- The labels used in Citation-Integrity (ACCURATE, NOT_ACCURATE, NEI) have different names but otherwise correspond to the labels used in MultiVerS (SUPPORT, REFUTE, NOT ENOUGH INFORMATION). Note: The IRRELEVANT label used in the paper of Sarol et al. (2024) maps to the NEI label in the Citation-Integrity dataset.\n",
    "- The baseline model in Citation-Integrity is MultiVerS trained on HealthVER.\n",
    "- I used the baseline model as the starting point for training on the Citation-Integrity dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576fdba-487b-4cf1-8bef-4c3ee4a4e8a4",
   "metadata": {},
   "source": [
    "# Model parameters and checkpoints\n",
    "\n",
    "The predictions made by the model at four checkpoints are compared below.\n",
    "These checkpoints are:\n",
    "\n",
    "- Model A (`bestModel-001.ckpt`): This is the best model from [Citation-Integrity](https://github.com/ScienceNLP-Lab/Citation-Integrity) and was downloaded from [Google Drive](https://drive.google.com/drive/u/0/folders/11b6Z8iv2FXObWmLaqfYzgUQsaL4QgTT2?q=parent:11b6Z8iv2FXObWmLaqfYzgUQsaL4QgTT2).\n",
    "- Model B (`citint_20241127.ckpt`): This is my first reproduction of the Citation-Integrity model. Except for modification made to `requirements.txt` and imported packages, the codebase is identical to [this commit of Citation-Integrity](https://github.com/ScienceNLP-Lab/Citation-Integrity/commit/277152f9dfe3873455220f4cd15269474ab15617). This corresponds to commit [e10022](https://github.com/jedick/readycite/commit/e10022ecc4a24646708f6dd81e40f20208d62860).\n",
    "- Model C: (`citint_20241128.ckpt`): As in Model B, but with the dataset in `val_dataloader` changed from `\"test\"` to `\"val\"`. This corresponds to commit [cf8461](https://github.com/jedick/readycite/commit/cf846148c39557c45d99e2fcbb3409adea4fede3).\n",
    "- Model D: (`citint_20241129.ckpt`): As in Model C, but with the number of epochs in `train_target.py` changed from 5 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af60ae-91f5-460a-a787-e118d77005a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
