# Setup notes

This model is modified from from [MultiVerS](https://github.com/dwadden/multivers).
Some changes are ported from [Citation-Integrity](https://github.com/ScienceNLP-Lab/Citation-Integrity).

- See [README_multiverse.md](README_multiverse.md) for the original MultiVerS README.
- See [README_Citation-Integrity.md](README_Citation-Integrity.md) for the original Citation-Integrity README.


These notes were written by Jeffrey Dick in 2024.

### Training data

See `data` directory in the root this repo for training files.
Put `*.jsonl` files in:

- `data_train/target/citint` for Citation-Integrity ([2024 paper](https://doi.org/10.1093/bioinformatics/btae420)). Note: these are not the files in the Citation-Integrity [`data` directory](https://github.com/ScienceNLP-Lab/Citation-Integrity/tree/main/Data) but were downloaded from [Google Drive](https://drive.google.com/drive/u/0/folders/11b6Z8iv2FXObWmLaqfYzgUQsaL4QgTT2?q=parent:11b6Z8iv2FXObWmLaqfYzgUQsaL4QgTT2).
- `data_train/target/scifact_10` for SciFact (10 negative samples per positive - [2022 paper](https://arxiv.org/abs/2210.13777))
- `data_train/target/scifact_20` for SciFact (20 negative samples per positive - [2021 paper](https://arxiv.org/abs/2112.01640))
- `data_train/target/scifact` for SciFact (original version - [2020 paper](https://arxiv.org/abs/2004.14974))

### Setup conda environment with working Python version

```
conda create -n multivers python=3.8
conda activate multivers
```

### Install required packages for MultiVerS

```
conda install --file requirements.txt -c conda-forge
```

Notes:

- Minimized list of packages in requirements.txt and renamed torch to pytorch
- Use -c conda-forge to avoid this error: PackagesNotFoundError: The following packages are not available from current channels


### Install the CUDA flavor of PyTorch

Run `nvidia-smi` to check CUDA version of the GPU.
Then run this command from the [PyTorch website](https://pytorch.org/get-started/previous-versions/#v171):

```
conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch
```

Note: run this *after* installing packages from requirements.txt to avoid error with pandas import (ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject).

### Download checkpoints

MultiVerS start training from the `fever_sci` checkpoint.
Citation-Integrity starts training from the `healthver` checkpoint.
Note: I modified the wget command in `get_checkpoint.py` to continue interrupted downloads.

```
python script/get_checkpoint.py fever_sci
python script/get_checkpoint.py healthver
```

### Download transformers

Running the training script will automatically download transformers from huggingface.
Sometimes getting an error, just try again (ValueError: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on).

```
python script/train_target.py --dataset citint --gpus=1
```

### Train the model and make predictions

This takes about 3 hours for 5 epochs.
Results are saved in `checkpoints_user`; use last.ckpt for the predictions.
See [David Wadden's notes about training](https://github.com/dwadden/multivers/blob/main/doc/training.md).

```
CUDA_LAUNCH_BLOCKING=1 TOKENIZERS_PARALLELISM=false python script/train_target.py --dataset citint --gpus=1 --gradient_checkpointing
```

Make predictions - takes about 1.5 minutes.
NOTE: This requires the `train_configs.json` file generated by the training to be present in the current directory.

```
python src/predict.py \
  --checkpoint_path=checkpoints/last.ckpt \
  --input_file=data_train/target/citint/claims_test.jsonl \
  --corpus_file=data_train/target/citint/corpus.jsonl \
  --output_file=predictions.jsonl
```

### Train the model on SciFact

Takes about 1.5 hours for 5 epochs.

```
CUDA_LAUNCH_BLOCKING=1 TOKENIZERS_PARALLELISM=false python script/train_target.py --dataset scifact --gpus=1 --gradient_checkpointing
```

Note: `scifact` is the original SciFact dataset.
Use `scifact_10` or `scifact_20` for the datasets with negative sampling.

### Change log

Modifications made by JMD:

- [[3e6935](https://github.com/jedick/ReadyCite/commit/3e69357ba6da88f9eea85e13f86cf9e7077811bd)] 2024-12-16 Commit MultiVerS codebase followed by these changes:
	- Update `requirements.txt` with minimal list of packages
	- `num_epochs` changed from 20 to 5
	- Add support for Citation-Integrity (`citint`) and original SciFact (`scifact`) datasets
	- Normalize labels in datasets (`SUPPORT`, `REFUTE`, `NEI`)
- [[13ebe7](https://github.com/jedick/ReadyCite/commit/13ebe74cb872e1344d352d630f11d4b8e4be67cf)] 2024-11-27 Commit Citation-Integrity codebase (source: [277152](https://github.com/ScienceNLP-Lab/Citation-Integrity/commit/277152f9dfe3873455220f4cd15269474ab15617)) to show diffs from MultiVerS (source: [a6ce03](https://github.com/dwadden/multivers/commit/a6ce033f0e17ae38c1f102eae1ee4ca213fbbe2e)). Some changes in CitationIntegrity are:
	- Changes the number of epochs for training from 20 to 5
	- Adds three tokens (`<|cit|>`, `<|multi_cit|>`, `<|other_cit|>`) 
	- Has `"test"` rather than `"val"` in `val_dataloader` 
	- Changes `rationale_weight` from 15 to 0.
